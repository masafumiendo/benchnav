{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial #2: Traversability Prediction Models\n",
    "\n",
    "This tutorial briefly explains how to predict traversability for motion planning algorithms. We assume there are ten distinct terrain classes in planetary surface environments and each has a latent slip model. In order to predict traversability map, it is necessary to first identify distinct terrain types then predict individual models mapping terrain geometry to slip behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before starting\n",
    "\n",
    "Before starting this tutorial, you can download [datasets and trained models](https://github.com/masafumiendo/benchnav/releases/tag/v0.0). These folders contain a dataset to train terrain classifier and slip regressors as well as pretrained ML models based on PyTorch (and GPyTorch).\n",
    "\n",
    "- datasets: this folder contains datasets for training terrain classifiers in `train` and `valid,` and training slip regressors in `slip_models.` In the `test` folder, there are testing subsets used for motion planning environments.\n",
    "- trained_models: this folder contains trained ML models. As a terrain classifier, we adopt a simple Unet. As slip regressors, we use Gaussian process regressors implemented in gpytorch.\n",
    "\n",
    "You can download `datasets.zip` and `trained_models.zip` and place them as `./datasets` and `./trained_models` after unzipping them, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "# Add the parent directory to the path so that the environment can be found\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "\n",
    "# Import the necessary libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "\n",
    "# Import the necessary classes\n",
    "from src.prediction_models.terrain_classifiers.unet import Unet\n",
    "from src.prediction_models.slip_regressors.gpr import GPModel\n",
    "from src.prediction_models.traversability_predictors.classifier_and_regressor import (\n",
    "    TraversabilityPredictor,\n",
    ")\n",
    "from src.prediction_models.trainers.utils import ParamsModelTraining\n",
    "from src.prediction_models.trainers.utils import load_model_state_dict\n",
    "from src.data.terrain_dataset import TerrainClassificationDataset as TCDataset\n",
    "from src.data.terrain_dataset import TraversabilityPredictionDataset as TPDataset\n",
    "from src.data.slip_models_generator import SlipModelsGenerator\n",
    "\n",
    "sns.set()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terrain Classification based on CNN\n",
    "\n",
    "Semantic scene understanding is crucial for predicting traversability, as different material properties cause different risks of immobility. Terrain classification is performed for this purpose by taking RGB color images to categorize distince terrain types. We adopt a simple Unet as a terrain classifier and you can see how Unet conducts terrain classifications as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the pretrained `Unet` from unzipped `trained_models`. The class `ParamsModelTraining` specifies training conditions of Unet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_terrain_classes = 10\n",
    "terrain_classifier = Unet(num_total_terrain_classes).to(device)\n",
    "\n",
    "dataset_index = 1\n",
    "\n",
    "# Set the model directory\n",
    "base_directory = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "model_directory = os.path.join(\n",
    "    base_directory, f\"trained_models/dataset{dataset_index:02d}/Unet/\"\n",
    ")\n",
    "\n",
    "# Set the parameters for model training\n",
    "params_model_training = ParamsModelTraining(\n",
    "    batch_size=16,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=0e00,\n",
    "    num_epochs=100,\n",
    "    save_interval=None,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Load the trained model\n",
    "model_directory = os.path.join(\n",
    "    model_directory,\n",
    "    f\"bs{params_model_training.batch_size:03d}_\"\n",
    "    f\"lr{params_model_training.learning_rate:.0e}_\"\n",
    "    f\"wd{params_model_training.weight_decay:.0e}_\"\n",
    "    f\"epochs{params_model_training.num_epochs:03d}\",\n",
    "    \"models/best_model.pth\",\n",
    ")\n",
    "\n",
    "terrain_classifier = load_model_state_dict(terrain_classifier, model_directory, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the testing dataset from unzipped `datasets` and perform terrain classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data directory\n",
    "data_directory = os.path.join(base_directory, f\"datasets/dataset{dataset_index:02d}/\")\n",
    "subset_index = 1\n",
    "\n",
    "test_dataset = TCDataset(data_directory, \"test\", subset_index, device)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Test the model\n",
    "for index, (colors, t_classes) in enumerate(test_loader):\n",
    "    colors = colors.to(device)\n",
    "    t_classes = t_classes.to(device)\n",
    "    predicted = terrain_classifier.predict(colors)\n",
    "\n",
    "    # Data conversion for visualization\n",
    "    colors = colors.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
    "    t_classes = t_classes.squeeze(0).cpu().numpy()\n",
    "    predicted = predicted.squeeze(0).cpu().detach().numpy()\n",
    "\n",
    "    # Visualization\n",
    "    _, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # Input Image\n",
    "    axs[0].imshow(colors)\n",
    "    axs[0].set_title(\"Input Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    # Ground Truth\n",
    "    axs[1].imshow(t_classes, cmap=\"jet\")\n",
    "    axs[1].set_title(\"Ground Truth\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    # Predicted\n",
    "    axs[2].imshow(predicted, cmap=\"jet\")\n",
    "    axs[2].set_title(\"Prediction\")\n",
    "    axs[2].axis(\"off\")\n",
    "\n",
    "    # Break the loop after some iterations\n",
    "    if index == 2:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slip Regression based on GPR\n",
    "\n",
    "The primary purpose of slip regression is to project terrain geometry to slip behavior for symbolically categorized terrain classes. We use Gaussian process regressions (GPR) for this purpose, since it can not only predict nonlinear slip functions but also give us its probability distributions. This enables risk-aware decision makings such as using VaR or CVaR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the pretrained `GPR` from unzipped `trained_models`. The class `ParamsModelTraining` specifies training conditions of GPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model directory\n",
    "model_directory = os.path.join(\n",
    "    base_directory, f\"trained_models/dataset{dataset_index:02d}/GPR/\"\n",
    ")\n",
    "# Set the parameters for model training\n",
    "params_model_training = ParamsModelTraining(\n",
    "    learning_rate=1e-1, num_iterations=100, device=device\n",
    ")\n",
    "model_directory = os.path.join(\n",
    "    model_directory,\n",
    "    f\"lr{params_model_training.learning_rate:.0e}_\"\n",
    "    f\"iters{params_model_training.num_iterations:03d}\",\n",
    ")\n",
    "\n",
    "# Set the data directory\n",
    "data_directory = os.path.join(\n",
    "    base_directory, f\"datasets/dataset{dataset_index:02d}/slip_observations/\"\n",
    ")\n",
    "\n",
    "all_gp_models = {}  # Dictionary to store the GP model\n",
    "all_train_data = {}  # Dictionary to store the training data\n",
    "for i in range(num_total_terrain_classes):\n",
    "    # Load the training data\n",
    "    train_data = torch.load(\n",
    "        os.path.join(data_directory, f\"{i:02d}_class.pth\"), map_location=device\n",
    "    )\n",
    "    train_x = train_data[\"train_x\"].to(device)\n",
    "    train_y = train_data[\"train_y\"].to(device)\n",
    "    # Initialize the GP model\n",
    "    likelihood = GaussianLikelihood().to(device=device)\n",
    "    gp_model = GPModel(train_x, train_y, likelihood).to(device)\n",
    "    # Load the trained model\n",
    "    gp_model = load_model_state_dict(\n",
    "        gp_model,\n",
    "        os.path.join(model_directory, f\"models/{i:02d}_class.pth\"),\n",
    "        device,\n",
    "    )\n",
    "    # Store the model\n",
    "    all_gp_models[i] = gp_model\n",
    "    # Store the training data\n",
    "    all_train_data[i] = train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the actual slip models for reference. The `SlipModelsGenerator` class plays this role by replicating latent slip models for reproductivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the actual model for reference\n",
    "slip_sensitivity_minmax = (1.0, 9.0)\n",
    "slip_nonlinearity_minmax = (1.4, 2.0)\n",
    "slip_offset_minmax = (0.0, 0.1)\n",
    "noise_scale_minmax = (0.1, 0.2)\n",
    "\n",
    "# Generate the slip models\n",
    "slip_models_generator = SlipModelsGenerator(\n",
    "    num_total_terrain_classes=num_total_terrain_classes,\n",
    "    slip_sensitivity_minmax=slip_sensitivity_minmax,\n",
    "    slip_nonlinearity_minmax=slip_nonlinearity_minmax,\n",
    "    slip_offset_minmax=slip_offset_minmax,\n",
    "    noise_scale_minmax=noise_scale_minmax,\n",
    "    device=device,\n",
    ")\n",
    "slip_models = slip_models_generator.generate_slip_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Visualize GPR predictions and actual slip models in order to see how GPR captures slope-slip behaviors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare figure for subplots\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2, ncols=5, figsize=(20, 8)\n",
    ")  # Adjust nrows and ncols based on your preference\n",
    "fig.suptitle(\"GPR Predictions vs. Actual Slip Models\")\n",
    "\n",
    "test_phis = torch.linspace(0, 30, 100).to(device=device)\n",
    "for i in range(num_total_terrain_classes):\n",
    "    # Test the trained GP model\n",
    "    pred_dist = all_gp_models[i].predict(test_phis)\n",
    "    pred_mean = pred_dist.mean\n",
    "    pred_stddev = pred_dist.stddev\n",
    "    # Get the lower and upper confidence bounds\n",
    "    pred_lower, pred_upper = (\n",
    "        pred_mean - 2.0 * pred_stddev,\n",
    "        pred_mean + 2.0 * pred_stddev,\n",
    "    )\n",
    "\n",
    "    # Retrieve the actual slip model\n",
    "    slip_dist = slip_models[i].model_distribution(test_phis)\n",
    "    slip_mean = slip_dist.mean\n",
    "    slip_stddev = slip_dist.stddev\n",
    "    # Get the lower and upper confidence bounds\n",
    "    slip_lower, slip_upper = (\n",
    "        slip_mean - 2.0 * slip_stddev,\n",
    "        slip_mean + 2.0 * slip_stddev,\n",
    "    )\n",
    "\n",
    "    # Retrieve training data\n",
    "    train_x = all_train_data[i][\"train_x\"]\n",
    "    train_y = all_train_data[i][\"train_y\"]\n",
    "\n",
    "    # Pytorch -> Numpy\n",
    "    test_phis = test_phis.cpu().numpy()\n",
    "    pred_mean = pred_mean.cpu().numpy()\n",
    "    pred_lower = pred_lower.cpu().numpy()\n",
    "    pred_upper = pred_upper.cpu().numpy()\n",
    "    slip_mean = slip_mean.cpu().numpy()\n",
    "    slip_lower = slip_lower.cpu().numpy()\n",
    "    slip_upper = slip_upper.cpu().numpy()\n",
    "    train_x = train_x.cpu().numpy()\n",
    "    train_y = train_y.cpu().numpy()\n",
    "\n",
    "    # Visualization\n",
    "    # Plot the results in a subplot\n",
    "    ax = axes.flatten()[i]\n",
    "    # Actual model\n",
    "    ax.plot(test_phis, slip_mean, \"b\", label=\"Actual Model\")\n",
    "    ax.fill_between(\n",
    "        test_phis,\n",
    "        slip_lower,\n",
    "        slip_upper,\n",
    "        color=\"b\",\n",
    "        alpha=0.3,\n",
    "        label=\"Actual Confidence\",\n",
    "    )\n",
    "    # Training data\n",
    "    ax.scatter(train_x, train_y, color=\"b\", label=\"Training Data\", s=1)\n",
    "    # GP model\n",
    "    ax.plot(test_phis, pred_mean, \"r\", label=\"Predicted Mean\")\n",
    "    ax.fill_between(\n",
    "        test_phis,\n",
    "        pred_lower,\n",
    "        pred_upper,\n",
    "        color=\"r\",\n",
    "        alpha=0.3,\n",
    "        label=\"Predicted Confidence\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"Terrain {i+1}\")\n",
    "    ax.set_xlabel(\"Phi\")\n",
    "    ax.set_ylabel(\"Slip\")\n",
    "    ax.set_xlim([0, 30])\n",
    "    ax.set_ylim([0, 1])\n",
    "\n",
    "    # Convert the test_phis back to torch\n",
    "    test_phis = torch.from_numpy(test_phis).to(device=device)\n",
    "\n",
    "# Custom legend entries\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color=\"b\", label=\"Actual Model\"),\n",
    "    Line2D([0], [0], color=\"b\", alpha=0.5, label=\"Actual Confidence\", linewidth=10),\n",
    "    Line2D([0], [0], color=\"r\", label=\"Predicted Mean\"),\n",
    "    Line2D([0], [0], color=\"r\", alpha=0.5, label=\"Predicted Confidence\", linewidth=10),\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"w\",\n",
    "        label=\"Training Data\",\n",
    "        markerfacecolor=\"b\",\n",
    "        markersize=5,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Add the global legend\n",
    "fig.legend(\n",
    "    handles=legend_elements, loc=\"upper center\", ncol=5, bbox_to_anchor=(0.5, 0.05)\n",
    ")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traversability Prediction\n",
    "\n",
    "Given the multiple ML models, now you can predict traversability that considers both terrain geometry and appearance in complex off-road environments. Such traversability prediction map can be used for later motion planning problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set `TraversabilityPredictor` based on terrain classifer and slip regressors. You can simply provide already loaded models into the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traversability_predictor = TraversabilityPredictor(\n",
    "    terrain_classifier=terrain_classifier,\n",
    "    slip_regressors=all_gp_models,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Predict traversability by providing `colors` and `slopes` from map instances. The `predict` method returns `pred_dist` that is based on `torch.distributions.Normal` to represent probability distributions of traversability predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data directory\n",
    "data_directory = os.path.join(base_directory, f\"datasets/dataset{dataset_index:02d}/\")\n",
    "subset_index = 1\n",
    "\n",
    "test_dataset = TPDataset(data_directory, \"test\", subset_index, device)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Test the model\n",
    "for index, (colors, slopes, slips_mean, slips_stddev) in enumerate(test_loader):\n",
    "    colors = colors.to(device).squeeze(0)\n",
    "    slopes = slopes.to(device).squeeze(0)\n",
    "    pred_dist = traversability_predictor.predict(colors, slopes)\n",
    "\n",
    "    # Data conversion for visualization\n",
    "    slips_mean = slips_mean.cpu().detach().numpy().squeeze(0)\n",
    "    slips_stddev = slips_stddev.cpu().detach().numpy().squeeze(0)\n",
    "    pred_mean = pred_dist.mean.cpu().detach().numpy()\n",
    "    pred_stddev = pred_dist.stddev.cpu().detach().numpy()\n",
    "\n",
    "    # Visualization\n",
    "    _, axs = plt.subplots(1, 4, figsize=(18, 6))\n",
    "    # mean map\n",
    "    mean_img = axs[0].imshow(slips_mean, cmap=\"turbo\", vmin=0, vmax=1)\n",
    "    axs[0].set_title(\"Traversability Map - GT Mean\")\n",
    "    axs[0].axis(\"off\")\n",
    "    fig.colorbar(mean_img, ax=axs[0], orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "\n",
    "    # stddev map\n",
    "    stddev_img = axs[1].imshow(slips_stddev, cmap=\"turbo\", vmin=0.1, vmax=0.2)\n",
    "    axs[1].set_title(\"Traversability Map - GT Stddev\")\n",
    "    axs[1].axis(\"off\")\n",
    "    fig.colorbar(\n",
    "        stddev_img, ax=axs[1], orientation=\"vertical\", fraction=0.046, pad=0.04\n",
    "    )\n",
    "\n",
    "    mean_img = axs[2].imshow(pred_mean, cmap=\"turbo\", vmin=0, vmax=1)\n",
    "    axs[2].set_title(\"Traversability Map - Predict. Mean\")\n",
    "    axs[2].axis(\"off\")\n",
    "    fig.colorbar(mean_img, ax=axs[2], orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "\n",
    "    # stddev map\n",
    "    stddev_img = axs[3].imshow(pred_stddev, cmap=\"turbo\", vmin=0.1, vmax=0.2)\n",
    "    axs[3].set_title(\"Traversability Map - Predict. Stddev\")\n",
    "    axs[3].axis(\"off\")\n",
    "    fig.colorbar(\n",
    "        stddev_img, ax=axs[3], orientation=\"vertical\", fraction=0.046, pad=0.04\n",
    "    )\n",
    "\n",
    "    # Break the loop after some iterations\n",
    "    if index == 2:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
